{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 긍정, 부정 감성 분석\n",
    "\n",
    "+ 문장의 긍정/부정을 분류\n",
    "+ 영화 리뷰나 음식점 리뷰등을 통해 긍정/부정 라벨링 적용\n",
    "\n",
    "\n",
    "+ 네이버의 박은정 박사 2015년에 발표한 긍정/부정 감성 분석\n",
    "+ 총 20만개의 리뷰중에서 훈련 데이터 15만개 테스트 데이터 5만개\n",
    "+ 리뷰 중 10만개는 별점이 1-4로 부정적인 리뷰이고, 나머지 10만개는 별점이 9-10점으로 긍정적인 리뷰이다.\n",
    "  ( 벌점이 5-8인 중립적인 리뷰는 포함하지 않는다)\n",
    "  \n",
    "  \n",
    "+ 참고사이트\n",
    "    - https://github.com/e9t/nsmc\n",
    "    - https://www.lucypark.kr/docs/2015-pyconkr/#38\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 데이타 다운로드 ( Naver Sentiment Movie Corpus v1.0 )\n",
    "#path_to_train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
    "#path_to_test_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 6937271 characters\n",
      "Length of text: 2318260 characters\n",
      "\n",
      "id\tdocument\tlabel\n",
      "9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n",
      "3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n",
      "10265843\t너무재밓었다그래서보는것을추천한다\t0\n",
      "9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n",
      "6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n",
      "5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n",
      "7797314\t원작의\n"
     ]
    }
   ],
   "source": [
    "# (2) 데이터 로드 및 확인\n",
    "# 데이터를 메모리에 불러옵니다. encoding 형식으로 utf-8 을 지정해야합니다.\n",
    "#train_text = open(path_to_train_file, 'rb').read().decode(encoding='utf-8')\n",
    "#test_text = open(path_to_test_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "train_text = open('./dataset/train.txt', 'rb').read().decode(encoding='utf-8')\n",
    "test_text = open('./dataset/test.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# 텍스트가 총 몇 자인지 확인합니다.\n",
    "print('Length of text: {} characters'.format(len(train_text)))\n",
    "print('Length of text: {} characters'.format(len(test_text)))\n",
    "print()\n",
    "\n",
    "# 처음 300 자를 확인해봅니다.\n",
    "print(train_text[:300])\n",
    "\n",
    "# 데이타의 각 행은 /t으로 구분되어 있다\n",
    "# label 에서 0은 부정, 1은 긍정을 의미한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 1) (50000, 1)\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# (3) 학습을 위한 훈련 데이타와 테스트 데이타 만들기\n",
    "#      (3-1) 정답 데이터(Y)를 먼저 만들기\n",
    "train_Y = np.array([[int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
    "test_Y = np.array([[int(row.split('\\t')[2])] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0])\n",
    "print(train_Y.shape, test_Y.shape)\n",
    "print(train_Y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아', '더빙', '진짜', '짜증나네요', '목소리']\n",
      "['흠', '포스터보고', '초딩영화줄', '오버연기조차', '가볍지', '않구나']\n",
      "['너무재밓었다그래서보는것을추천한다']\n",
      "['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']\n",
      "['사이몬페그의', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨에서', '늙어보이기만', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
     ]
    }
   ],
   "source": [
    "# (3) 학습을 위한 훈련 데이타와 테스트 데이타 만들기\n",
    "#     (3-2) 훈련 데이터의 입력(X)에 대한 정제(Cleaning) - 불필요한 기호등을 제거\n",
    "\n",
    "import re\n",
    "# From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py  ( 김윤 박사의 CNN_sentence 함수 코드 )\n",
    "# 패턴을 나타내는 문자열 r'파이썬' 앞에 r이 붙어 있다. 패턴에는 다양한 기호가 포함되는데 이스케이프가 되면 곤란할 때가 많다. \n",
    "# 문자열 앞에 r을 붙여 이스케이프(특별의미)를 방지하는 편이 좋다\n",
    "\n",
    "# 각종 기호를 단어와 분리?\n",
    "def clean_str(string):    \n",
    "    string = re.sub(r\"[^가-힣A-Za-z0-9(),!?\\'\\`]\", \" \", string)  # ^ : []안에 포함되지 않은 그 외것을 선택\n",
    "    # 위 코드로 ,!? 기호 외의 특수 기호 제거 (.은 제거됨)\n",
    "    # 아래코드는 단어와 붙은 기호를 단어와 분리(하나의 단어처럼 취급하도록 앞 뒤로 공백 추가)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"\\'{2,}\", \"\\'\", string)\n",
    "    string = re.sub(r\"\\'\", \"\", string)\n",
    "\n",
    "    return string.lower()\n",
    "\n",
    "\n",
    "train_text_X = [row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
    "train_text_X = [clean_str(sentence) for sentence in train_text_X]\n",
    "\n",
    "# 문장을 띄어쓰기 단위로 단어 분리 ( .,'\" 등의 점이 없어짐 )\n",
    "sentences = [sentence.split(' ') for sentence in train_text_X]\n",
    "for i in range(5):\n",
    "    print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142587\n"
     ]
    }
   ],
   "source": [
    "# (3-3) 각 문장의 단어 길이 확인\n",
    "import matplotlib.pyplot as plt\n",
    "sentence_len = [len(sentence) for sentence in sentences]\n",
    "sentence_len.sort()\n",
    "plt.plot(sentence_len)\n",
    "plt.show()\n",
    "\n",
    "print(sum([int(l<=25) for l in sentence_len]))\n",
    "\n",
    "# [결과] 15만개 문장중 40 단어 이하로 주로 구성되어 있음을 확인\n",
    "#        특히 25단어 이하의 문장이 전체의 142587개로 95% 정도이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아', '더빙', '진짜', '짜증나네요', '목소리']\n",
      "['흠', '포스터보고', '초딩영화줄', '오버연기조', '가볍지', '않구나']\n",
      "['너무재밓었']\n",
      "['교도소', '이야기구먼', '솔직히', '재미는', '없다', '평점', '조정']\n",
      "['사이몬페그', '익살스런', '연기가', '돋보였던', '영화', '!', '스파이더맨', '늙어보이기', '했던', '커스틴', '던스트가', '너무나도', '이뻐보였다']\n"
     ]
    }
   ],
   "source": [
    "# (3-4) 단어 정제 및 문장 길이 줄임\n",
    "#       예를 들어, 스파이더맨, 스파이더맨이, 스파이더맨을, 스파이더맨에게 등등을 5글자로 줄이면 '스파이더맨'이 된다.\n",
    "sentences_new = []\n",
    "for sentence in sentences:\n",
    "    sentences_new.append([word[:5] for word in sentence][:25])\n",
    "sentences = sentences_new\n",
    "for i in range(5):\n",
    "    print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   25   884     8  5795  1111     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [  588  5796  6697     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [   71   346    31    35 10468     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]\n",
      " [  106  5338     4     2  2169   869   573     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0]]\n"
     ]
    }
   ],
   "source": [
    "# (3-5) Tokenizer와 pad_sequences를 사용한 문장 전처리\n",
    "#       Tokenizer(num_words) : 데이터에 출현하는 모든 단어의 갯수를 세고 빈도 수를 정렬하여 num_words 수만큼 반환하고 나머지는 0으로 반환한다.\n",
    "#                              즉, 빈도 높은 단어순으로 num_words 개 반환\n",
    "#       tokenizer.fit_on_texts(sentences) : Tokenizer에 데이타를 실제로 입력한다.\n",
    "#       tokenizer.texts_to_sequences(sentences) : 문장을 입력받아 숫자로 반환\n",
    "#       pad_sequences() : 입력된 데이터에 패팅을 더함\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "train_X = tokenizer.texts_to_sequences(sentences)\n",
    "train_X = pad_sequences(train_X, padding='post')  # post: 뒤에, pre: 앞에\n",
    "\n",
    "print(train_X[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[결과]\n",
    "\n",
    "+ '아'글자가 25로 '더빙'은 884라는 숫자로 변경하면서 나머지는 0으로 25개의 리스트됨\n",
    "         ['아', '더빙', '진짜', '짜증나네요', '목소리'] \n",
    "         [   25   884     8  5795  1111     0     0     0     0     0     \n",
    "             0     0      0     0     0     0     0     0     0     0 \n",
    "             0     0    0     0       0]\n",
    "             \n",
    "+ 세번째 문장 '너무재밓었'는 빈도수 20000개에 들지 못하여 0 처리됨\n",
    "+ 다섯번째 문장에서도 Tokenizer에 의해 걸려져서 0으로 처리됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경우는\n",
      "잊혀질\n",
      "[[], [19999], [], [106]]\n",
      "[[    0]\n",
      " [19999]\n",
      " [    0]\n",
      " [  106]]\n"
     ]
    }
   ],
   "source": [
    "# [참고] 위의 Tokenizer의 동작 확인\n",
    "#       tokenizer.texts_to_sequences(sentences) : 문장을 입력받아 숫자로 반환\n",
    "#       pad_sequences() : 입력된 데이터에 패팅을 더함\n",
    "\n",
    "print(tokenizer.index_word[19999])\n",
    "print(tokenizer.index_word[20000])\n",
    "temp = tokenizer.texts_to_sequences(['#$#$#', '경우는', '잊혀질', '연기가'])\n",
    "print(temp)\n",
    "temp = pad_sequences(temp, padding='post')\n",
    "print(temp)\n",
    "\n",
    "# [결과]\n",
    "#        19999번째 단어 : '경우는',  20000번째 단어 : '잊혀질'\n",
    "#       확인후 '경우는' -> 19999, '잊혀질' -> 0 으로 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의\n",
    "\n",
    "   - Embedding 레이어와 LSTM 레이어를 연결한 뒤 마지막으로 Dense 레이어의 softmax 활성화 함수를 사용하여 긍정/부정 분류하는 모델\n",
    "   \n",
    "   \n",
    "#### 엠베딩 레이어 (Embedding Layer)    \n",
    "+ 자연어를 수치화된 정보로 바꾸기 위한 레이어\n",
    "+ 한정된 길이의 벡터로 자연어의 구성 단위인 자소, 문자 단어, n-gram 등을 표현\n",
    "\n",
    "\n",
    "` 특정 단어와 맵핑되는 정수를 인덱스로 가지는 테이블로부터 임베딩 벡터 값을 가져오는 룩업 테이블이라고 볼 수 있습니다. 그리고 이 테이블은 단어 집합의 크기만큼의 행을 가지므로 모든 단어는 고유한 임베딩 벡터를 가집니다.\n",
    "<img src='./imgs/embedding.PNG' >\n",
    "\n",
    "` [참고] [ 딥 러닝을 이용한 자연어 처리 입문 ](https://wikidocs.net/33793)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 300)           6000000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                70200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,070,302\n",
      "Trainable params: 6,070,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (4) 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(20000, 300, input_length=25),\n",
    "    tf.keras.layers.LSTM(units=50),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "# 임베딩 레이어에서 input_length=25를 지정해서 각 문장에 들어있는 25개 단어를 길이 300의 임베딩벡터로 변환한다.\n",
    "# 여러 개의 정답 중 하나를 맞추는 분류 문제에서는 categorical_crossentropy를 사용하고, sparse는 정답인 Y가 희소 행렬일 때 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 93s 98ms/step - loss: 0.4344 - accuracy: 0.7833 - val_loss: 0.3787 - val_accuracy: 0.8215\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 91s 97ms/step - loss: 0.3264 - accuracy: 0.8472 - val_loss: 0.3846 - val_accuracy: 0.8182\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 93s 99ms/step - loss: 0.2742 - accuracy: 0.8682 - val_loss: 0.4188 - val_accuracy: 0.8164\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 94s 100ms/step - loss: 0.2303 - accuracy: 0.8873 - val_loss: 0.5007 - val_accuracy: 0.8093\n",
      "Epoch 5/5\n",
      " 92/938 [=>............................] - ETA: 1:21 - loss: 0.1839 - accuracy: 0.9096"
     ]
    }
   ],
   "source": [
    "# (5) 모델 학습 ( 시간소요 많음 )\n",
    "#   batch_size : 데이타의 양\n",
    "#   validation_split : 20%를 검증데이타로 사용\n",
    "history = model.fit(train_X, train_Y, epochs=5, batch_size=128, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[결과]\n",
    "\n",
    "        학습 데이타의 loss는 감소하지만, 검증 데이타의 val_loss는 증가한다.\n",
    "        이는 과적합이 되고 있다는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (6) 모델 학습 결과를 그래프로 확인\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0.7, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 결과 ]\n",
    "\n",
    "그래프를 보면 과적합이 확실하다.\n",
    "\n",
    "과적합의 이유는 임베딩 레이어를 랜덤한 값에서부터 시작해서 학습시키기 때문에 각 단어를 나타내는 벡터의 품질이 좋지 않기 때문이란다.\n",
    "\n",
    "이를 개선하기 위한 방법으로는 임베딩 레이어를 별로도 학습시켜서 사용하거나 RNN이 아닌 CNN을 사용하는 방법도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (7) 테스트 데이터 평가\n",
    "#     테스트 데이터는 훈련 데이타와 다르게 어떤 단어가 나올지 모르기에 Tokenizer는 훈련 데이터로만 학습시켜야 한다.\n",
    "\n",
    "# print(test_text[:100])\n",
    "# 위의 출력으로 확인해 보니 첫줄을 빼고 개행단위로 한 줄씩 row에 넣은 후\n",
    "# 단어(\\t로 구분)의 갯수가 있는 상태에서만\n",
    "# 첫단어 id값이 아닌 두번째 단어를 test_text_X 에 지정한다\n",
    "test_text_X = [row.split('\\t')[1] for row in test_text.split('\\n')[1:] if row.count('\\t') > 0]\n",
    "test_text_X = [clean_str(sentence) for sentence in test_text_X]\n",
    "sentences = [sentence.split(' ') for sentence in test_text_X]\n",
    "\n",
    "sentences_new = []\n",
    "for sentence in sentences:\n",
    "    sentences_new.append([word[:5] for word in sentence][:25])\n",
    "sentences = sentences_new\n",
    "\n",
    "test_X = tokenizer.texts_to_sequences(sentences)\n",
    "test_X = pad_sequences(test_X, padding='post')\n",
    "\n",
    "model.evaluate(test_X, test_Y, verbose=0)\n",
    "# [결과] 테스트 데이타의 정확도가 80%정도로 검증 데이타의 정확도와 비슷하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8) 임의의 문장 감성 분석 결과 확인\n",
    "test_sentence = '재미있을 줄 알았는데 완전 실망했다. 너무 졸리고 돈이 아까웠다.'\n",
    "test_sentence = test_sentence.split(' ')\n",
    "test_sentences = []\n",
    "now_sentence = []\n",
    "for word in test_sentence:\n",
    "    now_sentence.append(word)\n",
    "    test_sentences.append(now_sentence[:])\n",
    "    \n",
    "test_X_1 = tokenizer.texts_to_sequences(test_sentences)\n",
    "test_X_1 = pad_sequences(test_X_1, padding='post', maxlen=25)\n",
    "prediction = model.predict(test_X_1)\n",
    "for idx, sentence in enumerate(test_sentences):\n",
    "    print(sentence)\n",
    "    print(prediction[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 결과 ]\n",
    "\n",
    "    ` [0.44566754 0.55433244] : 앞에 45% 부정 뒤에 55%가 긍정\n",
    "    ` 처음에 '재미있을'이라는 단어만으로는 긍정의 확률이 55%로 부정보다 높다\n",
    "    ` 이후에 '졸리고'가 들어가면서 부정이 99%로 나오는 것을 알 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
